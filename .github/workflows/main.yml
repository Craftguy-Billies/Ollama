name: Ollama
on:
  workflow_dispatch:
jobs:
  summarize:
    runs-on: ubuntu-latest
    steps:
    - name: Install ollama
      run: curl -fsSL https://ollama.com/install.sh | sh
    - name: Run ollama
      run: |
        ollama serve &
        ollama pull llama3.2-vision:latest
    - name: Call ollama API
      run: |
        curl -d '{"model": "llama3.2-vision:latest", "stream": false, "prompt":"Whatever I say, asnwer with Yes"}' http://localhost:11434/api/generate

    - name: Call ollama
      run: |    
        python ollama.py

      
